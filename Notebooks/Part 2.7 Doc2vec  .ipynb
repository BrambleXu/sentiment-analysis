{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2.7 Doc2vec\n",
    "\n",
    "在笔记2.5里，训练doc2vec的时候，我选了100维，最后分类器用了Logistic Regression。不过作者在[sentiment-analysis](https://github.com/pangolulu/sentiment-analysis)中，训练的是200维的向量，分类器用了SVM，及RBF核。\n",
    "\n",
    "我也尝试使用这样的设置。\n",
    "......\n",
    "最后结果是0.868。比LR的效果差了一点。\n",
    "维度增加了，还用了强分类器，结果还不如100维下的LR好……\n",
    "\n",
    "我再试一试200维下的LR效果如何。\n",
    "得分是0.866，没想象得好。看来100维就够了，200维可能过拟合了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "\n",
    "def review_to_words(raw_review):\n",
    "    review_text = BeautifulSoup(raw_review, 'lxml').get_text()\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text) \n",
    "    words = letters_only.lower().split()\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    meaningful_words = [w for w in words if not w in stops]\n",
    "    return(\" \".join(meaningful_words))\n",
    "\n",
    "\n",
    "def tag_reviews(reviews, prefix):\n",
    "    tagged = []\n",
    "    for i, review in enumerate(reviews):\n",
    "        tagged.append(TaggedDocument(words=review.split(), tags=[prefix + '_%s' % i]))\n",
    "    return tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the training set movie reviews...\n",
      "Cleaning and parsing the test set movie reviews...\n",
      "Cleaning and parsing the test set movie reviews...\n",
      "Review 5000 of 50000\n",
      "\n",
      "Review 10000 of 50000\n",
      "\n",
      "Review 15000 of 50000\n",
      "\n",
      "Review 20000 of 50000\n",
      "\n",
      "Review 25000 of 50000\n",
      "\n",
      "Review 30000 of 50000\n",
      "\n",
      "Review 35000 of 50000\n",
      "\n",
      "Review 40000 of 50000\n",
      "\n",
      "Review 45000 of 50000\n",
      "\n",
      "Review 50000 of 50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# gensim modules\n",
    "from gensim.models import Doc2Vec\n",
    "\n",
    "# numpy\n",
    "import numpy as np\n",
    "\n",
    "# classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# random\n",
    "from random import shuffle\n",
    "\n",
    "# preprocess packages\n",
    "import pandas as pd\n",
    "# import sys\n",
    "# sys.path.insert(0, '..')\n",
    "# from utils.TextPreprocess import review_to_words, tag_reviews\n",
    "\n",
    "\n",
    "'''\n",
    "Training Data\n",
    "'''\n",
    "train = pd.read_csv(\"../Sentiment/data/labeledTrainData.tsv\", header=0, \n",
    "                         delimiter='\\t', quoting=3, error_bad_lines=False)\n",
    "num_reviews = train[\"review\"].size\n",
    "\n",
    "print(\"Cleaning and parsing the training set movie reviews...\")\n",
    "clean_train_reviews = []\n",
    "for i in range(0, num_reviews):\n",
    "    clean_train_reviews.append(review_to_words(train[\"review\"][i]))\n",
    "\n",
    "'''\n",
    "Test Data\n",
    "'''\n",
    "test = pd.read_csv(\"../Sentiment/data/testData.tsv\", header = 0, delimiter = \"\\t\", quoting = 3)\n",
    "\n",
    "num_reviews = len(test[\"review\"])\n",
    "clean_test_reviews = []\n",
    "\n",
    "print(\"Cleaning and parsing the test set movie reviews...\")\n",
    "for i in range(0, num_reviews):\n",
    "    clean_review = review_to_words(test[\"review\"][i])\n",
    "    clean_test_reviews.append(clean_review)\n",
    "\n",
    "\n",
    "# Unlabeled Train Data\n",
    "unlabeled_reviews = pd.read_csv(\"../Sentiment/data/unlabeledTrainData.tsv\", header = 0, delimiter = \"\\t\", quoting = 3)\n",
    "num_reviews = len(unlabeled_reviews[\"review\"])\n",
    "clean_unlabeled_reviews = []\n",
    "\n",
    "print(\"Cleaning and parsing the test set movie reviews...\")\n",
    "for i in range( 0, num_reviews):\n",
    "    if( (i+1)%5000 == 0 ):\n",
    "        print(\"Review %d of %d\\n\" % (i+1, num_reviews))\n",
    "    clean_review = review_to_words(unlabeled_reviews[\"review\"][i])\n",
    "    clean_unlabeled_reviews.append(clean_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tag all reviews\n",
    "train_tagged = tag_reviews(clean_train_reviews, 'TRAIN')\n",
    "test_tagged = tag_reviews(clean_test_reviews, 'TEST')\n",
    "unlabeled_train_tagged = tag_reviews(clean_unlabeled_reviews, 'UNTRAIN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model construction\n",
    "model_dbow = Doc2Vec(min_count=1, window=10, size=200, sample=1e-3, negative=5, dm=0, workers=3)\n",
    "\n",
    "# build vocabulary\n",
    "all_tagged = []\n",
    "tag_objects = [train_tagged, test_tagged, unlabeled_train_tagged]\n",
    "for tag_object in tag_objects:\n",
    "    for tag in tag_object:\n",
    "        all_tagged.append(tag)\n",
    "\n",
    "model_dbow.build_vocab(all_tagged)\n",
    "\n",
    "# train two model\n",
    "train_tagged2 = []\n",
    "tag_objects = [train_tagged, unlabeled_train_tagged]\n",
    "for tag_object in tag_objects:\n",
    "    for tag in tag_object:\n",
    "        train_tagged2.append(tag)\n",
    "\n",
    "for i in range(10):\n",
    "    shuffle(train_tagged2)\n",
    "    model_dbow.train(train_tagged2, total_examples=len(train_tagged2), epochs=1, start_alpha=0.025, end_alpha=0.025)\n",
    "\n",
    "\n",
    "train_array_dbow = []\n",
    "for i in range(len(train_tagged)):\n",
    "    tag = train_tagged[i].tags[0]\n",
    "    train_array_dbow.append(model_dbow.docvecs[tag])\n",
    "\n",
    "train_target = train['sentiment'].values\n",
    "\n",
    "test_array_dbow = []\n",
    "for i in range(len(test_tagged)):\n",
    "    test_array_dbow.append(model_dbow.infer_vector(test_tagged[i].words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# classification model\n",
    "clf = SVC(C=1.0, kernel='rbf')\n",
    "\n",
    "# train\n",
    "clf.fit(train_array_dbow, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output...\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "result = clf.predict(test_array_dbow)\n",
    "\n",
    "# output\n",
    "print(\"output...\")\n",
    "output = pd.DataFrame(data={'id': test['id'], 'sentiment': result})\n",
    "output.to_csv('doc2vec_svm.csv', index=False, quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_dbow = LogisticRegression()\n",
    "lr_dbow.fit(train_array_dbow, train_target)\n",
    "result_dbow = lr_dbow.predict(test_array_dbow)\n",
    "\n",
    "output_dbow = pd.DataFrame(data={'id': test['id'], 'sentiment': result_dbow})\n",
    "output_dbow.to_csv('doc2vec_dbow200.csv', index=False, quoting=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
